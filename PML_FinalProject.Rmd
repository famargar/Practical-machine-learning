---
title: "PML_FinalProject"
author: "Fabrizio"
date: "July 10, 2016"
output: html_document
---

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. The goal of your project is to predict the manner in which they did the exercise. 

The "classe" variable contains 5 levels: A,B,C,D,E. You may use any of the other variables to predict with. You should create a report describing 
1) how you built your model
2) how you used cross validation
3) what you think the expected out of sample error is
4) and why you made the choices you did. 
5) you will also use your prediction model to predict 20 different test cases.

Load packages

```{r}
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(corrplot))
```

Now read and clean data 

```{r}
training <- read.csv("pml-training.csv")
testing  <- read.csv("pml-testing.csv")
filter = grepl("belt|arm|dumbell|classe", names(training))
training = training[, filter]
testing = testing[, filter]
cols.without.na = colSums(is.na(testing)) == 0
training = training[, cols.without.na]
testing = testing[, cols.without.na]
```

Preprocessing

Trasnfor "classe" in a numeric columns. Check zero variance predictors. 

```{r}
num.class = length(levels(training$classe))
levels(training$classe) = 1:num.class
head(training)
zero.var = nearZeroVar(training, saveMetrics=TRUE)
zero.var
```

create a validation sample

```{r}
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
training <- training[inTrain, ]
validate <- training[-inTrain,]
```

now create a model training it on the 60% of the dataset provided in the project, using boosted decision trees.
Checking also the importance of the predictors.

```{r}
boostFit <- train(classe ~ ., method = "gbm", data = training, verbose = F, trControl = trainControl(method = "cv", number = 10))
boostFit
plot(boostFit, ylim = c(0.9, 1))
imp <- varImp(boostFit)$importance
imp$max <- apply(imp, 1, max)
imp <- imp[order(imp$max, decreasing = T), ]
```

Now estimate the out of sample error
```{r}
# predict on testValidateData
predictions <- predict(modelFit.rf, testValidateData)
# length of the predictions
length(predictions)
# true accuracy of the predicted model
outOfSampleError.accuracy <- sum(predictions == testValidateData$classe)/length(predictions)

outOfSampleError.accuracy

# out of sample error and percentage of out of sample error
outOfSampleError <- 1 - outOfSampleError.accuracy
outOfSampleError
e <- outOfSampleError * 100
paste0("Out of sample error estimation: ", round(e, digits = 2), "%")
```


prediction <- as.character(predict(boostFit, testing))
```

```{r}
# write prediction files
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./prediction/problem_id_", i, ".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, col.names = FALSE)
  }
}
pml_write_files(prediction)
```
